{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n"
   ],
   "id": "9967173c39f65e7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to check for missing weeks in time series data\n",
    "def check_missing_weeks(csv_file_path, date_column='WkStrtActual'):\n",
    "    \"\"\"\n",
    "    Check for missing weeks in a time series dataset.\n",
    "\n",
    "    Parameters:\n",
    "    csv_file_path (str): Path to the CSV file\n",
    "    date_column (str): Name of the column containing week start dates\n",
    "\n",
    "    Returns:\n",
    "    dict: Summary of missing weeks analysis\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        print(f\"Loaded {len(df)} rows from {csv_file_path}\")\n",
    "        print(f\"Columns in dataset: {list(df.columns)}\")\n",
    "    except FileNotFoundError:\n",
    "        return {\"error\": f\"File {csv_file_path} not found\"}\n",
    "\n",
    "    # Check if the date column exists\n",
    "    if date_column not in df.columns:\n",
    "        available_cols = [col for col in df.columns if 'date' in col.lower() or 'week' in col.lower() or 'time' in col.lower()]\n",
    "        return {\"error\": f\"Column '{date_column}' not found. Available date-like columns: {available_cols}\"}\n",
    "\n",
    "    # Convert date column to datetime\n",
    "    df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "    # Sort by date to ensure proper order\n",
    "    df = df.sort_values(date_column)\n",
    "\n",
    "    # Get unique week start dates\n",
    "    unique_weeks = df[date_column].drop_duplicates().sort_values()\n",
    "\n",
    "    # Get the date range\n",
    "    min_date = unique_weeks.min()\n",
    "    max_date = unique_weeks.max()\n",
    "\n",
    "    print(f\"Date range: {min_date.date()} to {max_date.date()}\")\n",
    "    print(f\"Number of unique weeks in data: {len(unique_weeks)}\")\n",
    "\n",
    "    # Generate expected weekly sequence\n",
    "    # Assuming weeks start on the same day of week as the first date\n",
    "    expected_weeks = []\n",
    "    current_week = min_date\n",
    "\n",
    "    while current_week <= max_date:\n",
    "        expected_weeks.append(current_week)\n",
    "        current_week += timedelta(days=7)\n",
    "\n",
    "    expected_weeks = pd.Series(expected_weeks)\n",
    "    print(f\"Expected number of weeks: {len(expected_weeks)}\")\n",
    "\n",
    "    # Find missing weeks\n",
    "    missing_weeks = expected_weeks[~expected_weeks.isin(unique_weeks)]\n",
    "\n",
    "    # Find extra weeks (shouldn't happen in a proper weekly sequence, but checking)\n",
    "    extra_weeks = unique_weeks[~unique_weeks.isin(expected_weeks)]\n",
    "\n",
    "    # Results summary\n",
    "    results = {\n",
    "        \"total_rows\": len(df),\n",
    "        \"unique_weeks_in_data\": len(unique_weeks),\n",
    "        \"expected_weeks\": len(expected_weeks),\n",
    "        \"missing_weeks_count\": len(missing_weeks),\n",
    "        \"extra_weeks_count\": len(extra_weeks),\n",
    "        \"date_range\": (min_date.date(), max_date.date()),\n",
    "        \"missing_weeks\": missing_weeks.dt.date.tolist() if len(missing_weeks) > 0 else [],\n",
    "        \"extra_weeks\": extra_weeks.dt.date.tolist() if len(extra_weeks) > 0 else [],\n",
    "        \"data_sample\": df.head()\n",
    "    }\n",
    "\n",
    "    return results\n"
   ],
   "id": "979f6caf7e2217ce"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check your specific file with the correct path\n",
    "file_path = \"data/sandiego_epideimilogy/Time_Series_0427D0184F5A45B7973E2512848A1EE4.csv\"\n",
    "\n",
    "# Run the missing weeks check\n",
    "missing_weeks_analysis = check_missing_weeks(file_path, 'WkStrtActual')\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MISSING WEEKS ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if \"error\" in missing_weeks_analysis:\n",
    "    print(f\"‚ùå Error: {missing_weeks_analysis['error']}\")\n",
    "else:\n",
    "    print(f\"üìä Total rows in dataset: {missing_weeks_analysis['total_rows']:,}\")\n",
    "    print(f\"üìÖ Unique weeks in data: {missing_weeks_analysis['unique_weeks_in_data']:,}\")\n",
    "    print(f\"üî¢ Expected weeks: {missing_weeks_analysis['expected_weeks']:,}\")\n",
    "    print(f\"‚ùì Missing weeks: {missing_weeks_analysis['missing_weeks_count']:,}\")\n",
    "    print(f\"üìà Date range: {missing_weeks_analysis['date_range'][0]} to {missing_weeks_analysis['date_range'][1]}\")\n",
    "\n",
    "    # Show first few rows of data for context\n",
    "    print(f\"\\nüìã Sample of data:\")\n",
    "    print(missing_weeks_analysis['data_sample'].to_string())\n",
    "\n",
    "    if missing_weeks_analysis['missing_weeks_count'] > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  MISSING WEEKS DETECTED ({missing_weeks_analysis['missing_weeks_count']} total):\")\n",
    "        for i, week in enumerate(missing_weeks_analysis['missing_weeks']):\n",
    "            if i < 20:  # Show first 20\n",
    "                print(f\"   - {week}\")\n",
    "            elif i == 20:\n",
    "                print(f\"   ... and {len(missing_weeks_analysis['missing_weeks']) - 20} more\")\n",
    "                break\n",
    "    else:\n",
    "        print(\"\\n‚úÖ NO MISSING WEEKS - Dataset is complete!\")\n",
    "\n",
    "    if missing_weeks_analysis['extra_weeks_count'] > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  UNEXPECTED WEEKS DETECTED: {missing_weeks_analysis['extra_weeks_count']}\")\n",
    "        for week in missing_weeks_analysis['extra_weeks']:\n",
    "            print(f\"   - {week}\")\n"
   ],
   "id": "2168c651d0067eeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Optional: Create a detailed week-by-week analysis\n",
    "def detailed_week_analysis(csv_file_path, date_column='WkStrtActual'):\n",
    "    \"\"\"\n",
    "    Create a detailed week-by-week analysis showing gaps\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        df[date_column] = pd.to_datetime(df[date_column])\n",
    "        df = df.sort_values(date_column)\n",
    "\n",
    "        # Get unique weeks and sort\n",
    "        unique_weeks = df[date_column].drop_duplicates().sort_values().reset_index(drop=True)\n",
    "\n",
    "        # Calculate gaps between consecutive weeks\n",
    "        gaps = []\n",
    "        for i in range(1, len(unique_weeks)):\n",
    "            current_week = unique_weeks.iloc[i]\n",
    "            previous_week = unique_weeks.iloc[i-1]\n",
    "            expected_next = previous_week + timedelta(days=7)\n",
    "\n",
    "            if current_week != expected_next:\n",
    "                gap_days = (current_week - expected_next).days\n",
    "                gap_weeks = gap_days // 7\n",
    "                gaps.append({\n",
    "                    'after_week': previous_week.date(),\n",
    "                    'before_week': current_week.date(),\n",
    "                    'gap_days': gap_days,\n",
    "                    'gap_weeks': gap_weeks,\n",
    "                    'missing_weeks': gap_weeks\n",
    "                })\n",
    "\n",
    "        return pd.DataFrame(gaps)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in detailed analysis: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Run detailed analysis\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETAILED GAP ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "gaps_df = detailed_week_analysis(file_path, 'WkStrtActual')\n",
    "if len(gaps_df) > 0:\n",
    "    print(\"üîç Gaps found in the time series:\")\n",
    "    print(gaps_df.to_string(index=False))\n",
    "    print(f\"\\nüìä Summary: {len(gaps_df)} gap(s) found, totaling {gaps_df['missing_weeks'].sum()} missing weeks\")\n",
    "else:\n",
    "    print(\"‚úÖ No gaps found - weeks are consecutive!\")\n"
   ],
   "id": "98f31afb974ad093"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Additional analysis: Show week distribution and patterns\n",
    "def week_pattern_analysis(csv_file_path, date_column='WkStrtActual'):\n",
    "    \"\"\"\n",
    "    Analyze weekly patterns in the data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        df[date_column] = pd.to_datetime(df[date_column])\n",
    "\n",
    "        # Add week information\n",
    "        df['year'] = df[date_column].dt.year\n",
    "        df['week_of_year'] = df[date_column].dt.isocalendar().week\n",
    "        df['day_of_week'] = df[date_column].dt.day_name()\n",
    "\n",
    "        print(\"\\nüìà WEEK PATTERN ANALYSIS\")\n",
    "        print(\"-\" * 40)\n",
    "        print(f\"Years covered: {df['year'].min():} - {df['year'].max()}\")\n",
    "\n",
    "        # Show basic distributions\n",
    "        print(\"\\nüìÖ Week Distribution:\")\n",
    "        print(df['week_of_year'].value_counts().sort_index())\n",
    "\n",
    "        print(\"\\n‚òÄÔ∏è Day of Week Distribution:\")\n",
    "        print(df['day_of_week'].value_counts())\n",
    "\n",
    "        # Show weekly trend\n",
    "        weekly_trend = df.groupby(['year', 'week_of_year']).size().reset_index(name='count')\n",
    "        print(\"\\nWeekly Trend:\")\n",
    "        print(weekly_trend.head())\n",
    "\n",
    "        # You can add more trend analysis here, like plotting, aggregation, etc.\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in week pattern analysis: {e}\")\n",
    "\n",
    "# Run week pattern analysis\n",
    "week_pattern_analysis(file_path, 'WkStrtActual')\n"
   ],
   "id": "3f1c93bc4389a118"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "import pandas as pd\n",
   "id": "5f2ca0336d1bb00d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-14T15:25:38.095330Z",
     "start_time": "2025-08-14T15:25:38.058190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate year, week, start date for weeks starting on Sunday (2020-2027)\n",
    "def generate_weekly_data(start_year=2020, end_year=2027):\n",
    "    \"\"\"\n",
    "    Generate year, week number, and start date for each week from start_year to end_year.\n",
    "    Weeks start on Sunday and follow ISO week numbering adjusted for Sunday start.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        # Start from January 1st of the year\n",
    "        current_date = pd.Timestamp(year, 1, 1)\n",
    "\n",
    "        # Find the first Sunday of the year or use Jan 1 if it's already Sunday\n",
    "        # Sunday = 6 in pandas (Monday = 0)\n",
    "        days_until_sunday = (6 - current_date.weekday()) % 7\n",
    "        first_sunday = current_date + pd.Timedelta(days=days_until_sunday)\n",
    "\n",
    "        # If Jan 1 is not Sunday and first Sunday is more than 3 days away,\n",
    "        # consider the week containing Jan 1 as week 1\n",
    "        if current_date.weekday() != 6 and days_until_sunday > 3:\n",
    "            # Start from the Sunday before Jan 1\n",
    "            first_sunday = current_date - pd.Timedelta(days=(current_date.weekday() + 1) % 7)\n",
    "\n",
    "        week_num = 1\n",
    "        week_start = first_sunday\n",
    "\n",
    "        # Generate weeks for the entire year\n",
    "        while week_start.year <= year:\n",
    "            if week_start.year == year or (week_start.year == year - 1 and week_start + pd.Timedelta(days=6) >= pd.Timestamp(year, 1, 1)):\n",
    "                results.append({\n",
    "                    'year': year,\n",
    "                    'week': week_num,\n",
    "                    'week_start_date': week_start.date()\n",
    "                })\n",
    "\n",
    "            week_start += pd.Timedelta(days=7)\n",
    "            week_num += 1\n",
    "\n",
    "            # Stop if we've moved to the next year and it's more than a few days in\n",
    "            if week_start.year > year and week_start > pd.Timestamp(year + 1, 1, 7):\n",
    "                break\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Generate the data\n",
    "weekly_data = generate_weekly_data(2020, 2027)\n",
    "\n",
    "# Display first few rows\n",
    "print(\"Sample of weekly data:\")\n",
    "print(weekly_data.head(10))\n",
    "\n",
    "# Show weeks per year to verify some years have 53 weeks\n",
    "weeks_per_year = weekly_data.groupby('year')['week'].max()\n",
    "print(\"\\nWeeks per year:\")\n",
    "print(weeks_per_year)\n",
    "\n",
    "# Show years with 53 weeks\n",
    "years_with_53_weeks = weeks_per_year[weeks_per_year == 53].index.tolist()\n",
    "print(f\"\\nYears with 53 weeks: {years_with_53_weeks}\")\n",
    "\n",
    "weekly_data"
   ],
   "id": "b0f2ac54ea26a6ce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of weekly data:\n",
      "   year  week week_start_date\n",
      "0  2020     1      2019-12-29\n",
      "1  2020     2      2020-01-05\n",
      "2  2020     3      2020-01-12\n",
      "3  2020     4      2020-01-19\n",
      "4  2020     5      2020-01-26\n",
      "5  2020     6      2020-02-02\n",
      "6  2020     7      2020-02-09\n",
      "7  2020     8      2020-02-16\n",
      "8  2020     9      2020-02-23\n",
      "9  2020    10      2020-03-01\n",
      "\n",
      "Weeks per year:\n",
      "year\n",
      "2020    53\n",
      "2021    52\n",
      "2022    52\n",
      "2023    53\n",
      "2024    53\n",
      "2025    53\n",
      "2026    52\n",
      "2027    52\n",
      "Name: week, dtype: int64\n",
      "\n",
      "Years with 53 weeks: [2020, 2023, 2024, 2025]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "     year  week week_start_date\n",
       "0    2020     1      2019-12-29\n",
       "1    2020     2      2020-01-05\n",
       "2    2020     3      2020-01-12\n",
       "3    2020     4      2020-01-19\n",
       "4    2020     5      2020-01-26\n",
       "..    ...   ...             ...\n",
       "415  2027    48      2027-11-28\n",
       "416  2027    49      2027-12-05\n",
       "417  2027    50      2027-12-12\n",
       "418  2027    51      2027-12-19\n",
       "419  2027    52      2027-12-26\n",
       "\n",
       "[420 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "      <th>week_start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-12-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>2020-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>5</td>\n",
       "      <td>2020-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>2027</td>\n",
       "      <td>48</td>\n",
       "      <td>2027-11-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2027</td>\n",
       "      <td>49</td>\n",
       "      <td>2027-12-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2027</td>\n",
       "      <td>50</td>\n",
       "      <td>2027-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>2027</td>\n",
       "      <td>51</td>\n",
       "      <td>2027-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>2027</td>\n",
       "      <td>52</td>\n",
       "      <td>2027-12-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows √ó 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
